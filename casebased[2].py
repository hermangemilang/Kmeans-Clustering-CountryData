# -*- coding: utf-8 -*-
"""CaseBased[2].ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ncy9Ljy0k1sOM4x01nB_5SWRIEJ4lzYq
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np; np.random.seed(1337)
import pandas as pd
import seaborn as sns; sns.set_theme()
import matplotlib.pyplot as plt; plt.style.use('fivethirtyeight')
# %matplotlib inline
import random
from matplotlib import style
style.use('ggplot')
from sklearn.preprocessing import scale, StandardScaler
from sklearn.cluster import AgglomerativeClustering, KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import plotly.express as px
!pip install -U kaleido
import kaleido
import warnings
warnings.filterwarnings('ignore')

"""###Explore Data"""

#Proses Pembacaan data
country = pd.read_csv('Country-data.csv')
#Menampilkan 5 data teratas
country.head()

#Menampilkan 5 data terbawah
country.tail()

#menampilkan jumlah baris dan kolom dalam bentuk dua dimensi
country.shape

# Mengecek banyaknya missing value
nans=pd.DataFrame(country.isnull().sum()).T
nans.rename(index={0:'# NaN'}, inplace=True); nans

#Melihat persebaran data setiap atribut
fig, axes = plt.subplots(4,2, figsize = (15,15))
sns.scatterplot(x = country['gdpp'], y = country['child_mort'], ax = axes[0,0], color = 'pink')
sns.scatterplot(x = country['income'], y = country['child_mort'], ax = axes[0,1], color = 'red')
sns.scatterplot(x = country['gdpp'], y = country['health'], ax = axes[1,0], color = 'pink')
sns.scatterplot(x = country['income'], y = country['health'], ax = axes[1,1], color = 'red')
sns.scatterplot(x = country['gdpp'], y = country['life_expec'], ax = axes[2,0], color = 'pink')
sns.scatterplot(x = country['income'], y = country['life_expec'], ax = axes[2,1], color = 'red')
sns.scatterplot(x = country['gdpp'], y = country['total_fer'], ax = axes[3,0], color = 'pink')
sns.scatterplot(x = country['income'], y = country['total_fer'], ax = axes[3,1], color = 'red')

plt.show()

# Menampilkan informasi statistik data
country.describe()

#Melihat Korelasi antar data
country_cor = country.corr()
country_cor

#Menampilikan korelasi dalam bentuk heatmap
mask = np.triu(np.ones_like(country_cor, dtype=np.bool))

fig, ax = plt.subplots(figsize=(15, 8))

cmap = sns.diverging_palette(220, 10, as_cmap=True)

sns.heatmap(country_cor, mask=mask, cmap=cmap, vmax=.3, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5},annot = True)

"""###Preprocessing Data"""

#Mendrop atribut country kemudian menormalisasi data
x = country.drop(columns=['country'])
scaler = StandardScaler()
x = pd.DataFrame(scaler.fit_transform(x), columns = x.columns)
x.head()

"""Data country di drop karena merupakan data dalam bentuk string, sedangkan beberapa pemrosesan berlangsung dengan mengandalkan nilai numerik"""

#Melihat data Outlier setiap atribut
fig = plt.figure(figsize = (20,16))
sns.boxplot(data=country)
plt.show()

# https://github.com/mfadhlim/Clustering-Countries_KMeans/blob/main/Clustering_Countries_Using_K-Means.ipynb
#handling outliers
def lower_upper(x) :
    q1 = np.percentile(x, 25)
    q3 = np.percentile(x, 75)
    iqr = q3-q1
    lower_bound = q1 - (iqr * 1.5)
    upper_bound = q3 + (iqr * 1.5)
    return lower_bound, upper_bound

def outliers(x) :
    lower_bound, upper_bound = lower_upper(x)
    return x[np.where((x>upper_bound) | (x<lower_bound))]

def remove_outliers(x) :
    q1 = x.quantile(0.25)
    q3 = x.quantile(0.75)
    iqr = q3-q1
    lower_bound = q1 - (iqr * 1.5)
    upper_bound = q3 + (iqr * 1.5)
    country_final = np.where(x>upper_bound, upper_bound,
                        np.where(x<lower_bound, lower_bound,
                          x))
    return country_final

print(outliers(country['child_mort'].values))
print(outliers(country['gdpp'].values))
print(outliers(country['life_expec'].values))
print(outliers(country['inflation'].values))
print(outliers(country['imports'].values))
print(outliers(country['exports'].values))
print(outliers(country['total_fer'].values))
print(outliers(country['health'].values))
print(outliers(country['income'].values))


country_new = country[['child_mort','exports','health','imports', 'income','inflation','life_expec','total_fer','gdpp']].apply(remove_outliers)

country_new

"""Saya memutuskan untuk menghapu data outliers dengan tujuan untuk menjaga keakuratan model """

#cek kembali data hasil handling outliers dari atribut Kesehatan
sns.set_theme(style="white")
plt.figure(figsize = (12,6))

ax = sns.boxplot(x=country_new["health"], data=country_new)
plt.show()

#cek kembali data hasil handling outliers dari atribut pendapatan
sns.set_theme(style="white")
plt.figure(figsize = (12,6))

ax = sns.boxplot(x=country_new["income"], data=country_new)
plt.show()

"""###Model(KMeans)"""

#Menentukan Jumlah cluster
SSD = []
cluster = range(1, 8)
for c in cluster:
    model = KMeans(n_clusters=c, random_state=0).fit(x)
    SSD.append(model.inertia_)

plt.plot(cluster, SSD, marker='o')
plt.title('Elbow Method',fontsize=10)
plt.xlabel('Clusters')
plt.ylabel('SSD')
plt.show()

#Sumber https://medium.com/@rishit.dagli/build-k-means-from-scratch-in-python-e46bf68aa875
class kmeans:
    
    def __init__(self, k=3, tol=0.001, max_iter=500):
        self.k = k
        self.tol = tol
        self.max_iter = max_iter

    # Training
    def fit(self, data):
      
        self.centroids = {}
        for i in range(self.k):
            self.centroids[i] = data[i]

        for i in range(self.max_iter):
            self.classifications = {}
            for i in range(self.k):
                self.classifications[i] = []
            for atribut in data:
                eucDistArr = []
                for centroid in self.centroids:
                    sum = 0
                    for j in range(len(atribut)):
                        subs_pow = (atribut[j] - self.centroids[centroid][j]) ** 2
                        sum += subs_pow
                    eucDist = sum ** (1/2)
                    eucDistArr.append(eucDist)
                classification = eucDistArr.index(min(eucDistArr))
                self.classifications[classification].append(atribut)

            prev_centroids = self.centroids
            for k in self.classifications:   
                for data in self.classifications[k]:
                    avgArr = [0.0 for _ in range(len(data))]
                    for i in range(len(data)):
                      avgArr[i] += data[i]
                for i in range(len(avgArr)):
                    avgArr[i] /= len(self.classifications[k])
                self.centroids[k] = avgArr
                
            stable = True
            for c in self.centroids:
                original_centroid = prev_centroids[c]
                current_centroid = self.centroids[c]
                subs = [0.0 for _ in range(len(original_centroid))]
                div = [0.0 for _ in range(len(original_centroid))]
                for i in range(len(original_centroid)):
                  subs[i] += current_centroid[i] - original_centroid[i]
                for i in range(len(original_centroid)):
                  div[i] = subs[i] / original_centroid[i] * 100.0
                error = 0
                for i in range(len(original_centroid)):
                  error += div[i]
                if error > self.tol:
                    stable = False
            if stable:
                break

    def predict(self, data):
        eucDistArr = []
        for centroid in self.centroids:
            sum = 0
            for i in range(len(data)):
                subs_pow = (data[i] - self.centroids[centroid][i]) ** 2
                sum += subs_pow
            eucDist = sum ** (1/2)
            eucDistArr.append(eucDist)
        classification = eucDistArr.index(min(eucDistArr))
        return classification

x = x.values
#Inisasiasi model
model = kmeans()
model.fit(x)

# Predict
fixCluster = np.zeros(shape=(167))
for i, d in enumerate(x):
  fixCluster[i] = model.predict(d)

fixCluster = fixCluster.astype('int32')
fixCluster

#Menampilkan data dengan cluster 0
country['cluster'] =fixCluster
country[country['cluster'] == 0][:10]

#Menampilkan data dengan cluster 1
country[country['cluster'] == 1][:10]

#Menampilkan data dengan cluster 2
country[country['cluster'] == 2][:10]

#Sumber https://www.kaggle.com/code/die9origephit/country-data-clustering-k-means-and-visualization

# Visualisasi hasil clustering dalam bentuk peta
country['cluster'].loc[country['cluster'] == 0] = 'Negara Miskin'
country['cluster'].loc[country['cluster'] == 1] = 'Negara Maju'
country['cluster'].loc[country['cluster'] == 2] = 'Negara Berkembang'

fig = px.choropleth(country[['country','cluster']],
                    locationmode = 'country names',
                    locations = 'country',
                    title = 'Daftar Kualitas Negara',
                    color = country['cluster'],  
                    color_discrete_map = {'Negara Miskin':'#FF6961',
                                        'Negara Maju':'#2ecc71',
                                        'Negara Berkembang':'#f8d66d'},
                    width=800, height=500
                   )
fig.update_geos(fitbounds = "locations", visible = True)
fig.update_layout(legend_title_text = 'Keterangan', legend_title_side = 'top', title_pad_l = 260, title_y = 0.85, title_x = 0.5)
fig.show(engine = 'kaleido')

"""###Evaluasi"""

#cek sihoutte score
n_clusters = [2, 3, 4, 5,6,7,8,9]

for cluster in n_clusters:
    
    # intialise kmeans
    kmeans = KMeans(n_clusters=cluster, max_iter=50,random_state= 100)
    kmeans.fit(country_new)
    
    cluster_labels = kmeans.labels_
    
    # silhouette score
    silhouette_avg = silhouette_score(country_new, cluster_labels)
    print("For n_clusters={0}, the silhouette score is {1}".format(cluster+1, silhouette_avg))